{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prathameshks/FileChat-Using-RAG/blob/main/fileChat-With-RAG-Simplified.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF spacy sentence-transformers bitsandbytes accelerate huggingface_hub"
      ],
      "metadata": {
        "id": "qQl0Kvvk_8fc",
        "outputId": "360a7b08-85f7-44e2-c544-1b5988e95b9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.10/dist-packages (1.24.12)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.44.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.44.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.2)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "JOQlAUpZ_Kcp",
        "outputId": "6200cbb1-17ce-4c78-8be2-62b0427803c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468,
          "referenced_widgets": [
            "ef0cdc97af2a44439324f2547fb94f8f",
            "abe3f5a3a8c5421aaaa2003aa067ca6b",
            "47d9c44537cf4b8faba1554cd5f136db",
            "6832dc89c35f4d7788a23e5140b3ef8f",
            "5c85d7472a8b482fbbe28b9dc3e3fb87",
            "286b2dd8693841c78a0ac6fa18bfe756",
            "36b3909b3c7248f6801891283e1e3462",
            "418a017529a74a848100fc0578f5cf81",
            "005cad0ea75d45ee9891a0a73a5ec711",
            "e223239ac1504ec5999e4089c018236c",
            "7f473623b581414ebbb0fe79d414c7b8"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Importing Required Libraries\n",
            "[INFO] Loading Dependencies\n",
            "[INFO] Sentencizer Installed\n",
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n",
            "[INFO] Huggingface Login Successful\n",
            "[INFO] Loading Embedding Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Loaded Embedding Model all-mpnet-base-v2\n",
            "[INFO] Using Attention Implementation: sdpa\n",
            "[INFO] Initialized Tokinizer for gemma-2-2b-it\n",
            "[INFO] Loading LLM Model gemma-2-2b-it\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef0cdc97af2a44439324f2547fb94f8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Loaded LLM Model gemma-2-2b-it\n",
            "[INFO] All Dependencies Loaded Successfully\n"
          ]
        }
      ],
      "source": [
        "print(\"[INFO] Importing Required Libraries\")\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import fitz\n",
        "from tqdm.auto import tqdm\n",
        "from spacy.lang.en import English\n",
        "from sentence_transformers import SentenceTransformer,util\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from huggingface_hub import login\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from transformers.utils import is_flash_attn_2_available\n",
        "import torch\n",
        "from google.colab import userdata, files\n",
        "from IPython.display import display, Markdown\n",
        "import random\n",
        "\n",
        "print(\"[INFO] Loading Dependencies\")\n",
        "nlp = English()\n",
        "nlp.add_pipe('sentencizer')\n",
        "print(\"[INFO] Sentencizer Installed\")\n",
        "\n",
        "login(token=userdata.get('HUGGINGFACE_TOKEN'))\n",
        "print(\"[INFO] Huggingface Login Successful\")\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# create embeddings using model all-mpnet-base-v2\n",
        "print(\"[INFO] Loading Embedding Model\")\n",
        "model = SentenceTransformer('all-mpnet-base-v2',device=device)\n",
        "print(\"[INFO] Loaded Embedding Model all-mpnet-base-v2\")\n",
        "\n",
        "\n",
        "# create quantization config\n",
        "# requires !pip install bitsandbytes accelerate\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "# 2 falsh attention is available use it for faster attention mechanism\n",
        "if (is_flash_attn_2_available()) and (torch.cuda.get_device_capability(0)[0] >= 8.0):\n",
        "    attn_implementation = \"flash_attention_2\"\n",
        "else:\n",
        "    attn_implementation = \"sdpa\"\n",
        "print(f\"[INFO] Using Attention Implementation: {attn_implementation}\")\n",
        "\n",
        "# instantiate tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b-it\") # This line was causing the error\n",
        "print(\"[INFO] Initialized Tokinizer for gemma-2-2b-it\")\n",
        "\n",
        "# instantiate model\n",
        "print(\"[INFO] Loading LLM Model gemma-2-2b-it\")\n",
        "llm_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"google/gemma-2-2b-it\",\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True,\n",
        "    attn_implementation=attn_implementation\n",
        ")\n",
        "print(\"[INFO] Loaded LLM Model gemma-2-2b-it\")\n",
        "\n",
        "llm_model.to(device)\n",
        "print(\"[INFO] All Dependencies Loaded Successfully\")\n",
        "\n",
        "chunk_embeddings = None\n",
        "chunk_list = None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_path:str) -> list[dict]:\n",
        "    doc = fitz.open(pdf_path)\n",
        "    page_list = []\n",
        "    for page_no,page in tqdm(enumerate(doc)):\n",
        "        text = page.get_text().replace('\\n', '').strip()\n",
        "\n",
        "        page_list.append({\n",
        "            'page_no': page_no,\n",
        "            'text': text,\n",
        "            'char_count': len(text),\n",
        "            'token_count':len(text)/4\n",
        "        })\n",
        "    return page_list"
      ],
      "metadata": {
        "id": "qdHKwu8X_7KH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chunking\n",
        "def make_chunks(page_list:list[dict], chunk_size:int = 10,overlap_sentences:int = 2,min_chunk_size:int = 100) -> list[dict]:\n",
        "    # text to sentences\n",
        "    for page in tqdm(page_list):\n",
        "        page['sentences'] = []\n",
        "        for sent in nlp(page['text']).sents:\n",
        "            page['sentences'].append(sent.text)\n",
        "        page['sentence_count'] = len(page['sentences'])\n",
        "\n",
        "    chunk_list = []\n",
        "    # sentences to seperate chunks of max chunk_size\n",
        "    for page in tqdm(page_list):\n",
        "        page['chunks'] = []\n",
        "        for i in range(0, page['sentence_count'], chunk_size-overlap_sentences):\n",
        "            page['chunks'].append(page['sentences'][i:i+chunk_size])\n",
        "        # make a chunk a special dict for further operations based on each chunk rather than a page\n",
        "        for chunk in page['chunks']:\n",
        "            chunk_item = {\n",
        "                'page_no': page['page_no'],\n",
        "                'text': ' '.join(chunk),\n",
        "                'sentence_count': len(chunk),\n",
        "            }\n",
        "            chunk_item['char_count'] = len(chunk_item['text'])\n",
        "            if chunk_item['char_count'] < min_chunk_size:\n",
        "                continue\n",
        "            chunk_item['token_count'] = len(chunk_item['text'])/4\n",
        "            chunk_list.append(chunk_item)\n",
        "\n",
        "    return chunk_list\n"
      ],
      "metadata": {
        "id": "MGX3fQsMBVEd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_embeddings(chunk_list:list[dict]) -> list[dict]:\n",
        "    # leverage GPU\n",
        "    chunk_texts = [chunk['text'] for chunk in chunk_list]\n",
        "    chunk_embeddings = model.encode(chunk_texts,batch_size=64,convert_to_tensor=False)\n",
        "    for i,chunk in tqdm(enumerate(chunk_list)):\n",
        "        chunk['embedding'] = chunk_embeddings[i]\n",
        "\n",
        "    return chunk_list"
      ],
      "metadata": {
        "id": "VnJX7pODGuIo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_embeddings(chunk_list:list[dict],save_path:str = 'embeddings.csv') -> None:\n",
        "    df = pd.DataFrame(chunk_list)\n",
        "    # df['embedding'] = df['embedding'].apply(lambda x: x.tolist())\n",
        "    df.to_csv(save_path,index=False)\n"
      ],
      "metadata": {
        "id": "q8_e_beQHqeC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def str_to_array(x:str) -> np.array:\n",
        "    return np.array(x.strip('[]').replace('\\n','').split(),dtype=np.float32)\n",
        "\n",
        "def load_embeddings(save_path:str = 'embeddings.csv') -> list[dict]:\n",
        "    df = pd.read_csv(save_path)\n",
        "    df['embedding'] = df['embedding'].apply(str_to_array)\n",
        "    # convert to list of dicts\n",
        "    chunk_list = df.to_dict(orient='records')\n",
        "    # for chunk in chunk_list:\n",
        "    #     chunk['embedding'] = torch.tensor(np.array(chunk['embedding'].tolist()),dtype = torch.float32).to(device)\n",
        "    return chunk_list\n"
      ],
      "metadata": {
        "id": "5RIpcs2AV-MP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a function to get top k result from embeddings\n",
        "def return_relevant_top_k(query:str,\n",
        "                          embeddings:torch.tensor,\n",
        "                          embedding_model:SentenceTransformer = model,\n",
        "                          k:int = 5,\n",
        "                          device:torch.device = device\n",
        "):\n",
        "    \"\"\"Return a top k result from embeddings based on dot product similarity with the query\n",
        "    input:\n",
        "        query: str Query to be searched\n",
        "        embeddings: torch.tensor Embeddings in which to search\n",
        "        embedding_model: SentenceTransformer = embedding_model Embedding model\n",
        "        k: int = 5\n",
        "        device: torch.device = device\n",
        "    output:\n",
        "        top_relevant_results: list[dict]\n",
        "    \"\"\"\n",
        "    # create embedding of query\n",
        "    query_embedding = embedding_model.encode(query, convert_to_tensor=True)\n",
        "    # dot product\n",
        "    dot_scores = util.dot_score(a=query_embedding,b=embeddings)[0]\n",
        "    # getting top k index and scores\n",
        "    top_k_dot_products = torch.topk(dot_scores,k=k)\n",
        "\n",
        "    return top_k_dot_products"
      ],
      "metadata": {
        "id": "kAzPqlQoLGdK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_relevent_top_k(top_k_dot_products:torch.tensor,chunk_list:list[dict]):\n",
        "    ans = []\n",
        "    for score,index in zip(top_k_dot_products.values,top_k_dot_products.indices):\n",
        "        relevent_chunk = chunk_list[index]\n",
        "        \"\"\"{{'page_no': 285,\n",
        "        'text': 'Insulin has an opposing hormone called glucagon. Glucagon-secreting cells in the pancreas sense the drop in glucose and, in response, release glucagon into the blood. Glucagon communicates to the cells in the body to stop using all the glucose. More specifically, it signals the liver to break down glycogen and release the stored glucose into the blood, so that glucose levels stay within the target range and all cells get the needed fuel to function properly. Figure 4.8 The Regulation of Glucose 244  |  Digestion and Absorption of Carbohydrates',\n",
        "         'sentence_count': 5, 'char_count': 549, 'token_count': 137.25, 'embedding'\n",
        "        \"\"\"\n",
        "        ans.append({\n",
        "            \"score\":score,\n",
        "            \"text\":relevent_chunk[\"text\"],\n",
        "            \"page_no\":relevent_chunk[\"page_no\"],\n",
        "            \"sentence_count\":relevent_chunk[\"sentence_count\"],\n",
        "            \"char_count\":relevent_chunk[\"char_count\"],\n",
        "            \"token_count\":relevent_chunk[\"token_count\"]\n",
        "        })\n",
        "    return ans"
      ],
      "metadata": {
        "id": "WodExA5BM_E5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_formatter(query: str,\n",
        "                     context_items: list[dict]) -> str:\n",
        "    # context = \"- \" + \"\\n- \".join([f\"({item['score']:.2f}) {item['text']}\" for item in context_items])\n",
        "\n",
        "    # base_prompt = f\"\"\"\n",
        "    # Based on the following context with there match score with the query in the starting parenthesis, Give me the answer for the query.\n",
        "    # Context : {context}\n",
        "\n",
        "    # Query : {query}\n",
        "\n",
        "    # Answer :\n",
        "    # \"\"\"\n",
        "    context = \", \\n\".join([item['text'] for item in context_items])\n",
        "\n",
        "    base_prompt = \"\"\"Please read the following context items, and then answer the question below based on the provided context, If Context is not sufficient then answer question on your own,\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\n",
        "Answer:\"\"\"\n",
        "    base_prompt = base_prompt.format(context=context,query=query)\n",
        "\n",
        "    # create prompt template\n",
        "    dialouge_template = [\n",
        "        {\n",
        "            \"role\":\"user\",\n",
        "            \"content\":base_prompt\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # apply template\n",
        "    prompt = tokenizer.apply_chat_template(conversation=dialouge_template,\n",
        "                                          tokenize=False,\n",
        "                                          add_generation_prompt=True)\n",
        "\n",
        "    # print(f\"Prompt: {prompt}\")\n",
        "\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "t-ZPQeeQPsxS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask(\n",
        "    query:str,\n",
        "    chunk_embeddings:torch.tensor,\n",
        "    chunk_list:list[dict],\n",
        "    embb_model:SentenceTransformer = model,\n",
        "    llm_model:AutoModelForCausalLM = llm_model,\n",
        "    tokenizer:AutoTokenizer = tokenizer,\n",
        "    k:int = 5,\n",
        "    temperature:float=0.7,\n",
        "    max_new_tokens:int=512,\n",
        "    device:torch.device = device if device else torch.device(\"cpu\")\n",
        ") -> str:\n",
        "    # get top k results ie retrival\n",
        "    top_k_results = return_relevant_top_k(query,chunk_embeddings,embb_model,k=k)\n",
        "    context_items = get_relevent_top_k(top_k_results,chunk_list)\n",
        "\n",
        "    # make prompt\n",
        "    prompt = prompt_formatter(query,context_items)\n",
        "    # print(prompt)\n",
        "\n",
        "    # tokenize\n",
        "    input_ids = tokenizer(prompt,return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # generate output\n",
        "    outputs = llm_model.generate(**input_ids,temperature=temperature,max_new_tokens=max_new_tokens,do_sample=True)\n",
        "\n",
        "    # output token to text\n",
        "    output_text = tokenizer.decode(outputs[0])\n",
        "\n",
        "    return output_text.replace(prompt,'')"
      ],
      "metadata": {
        "id": "Zc-CE4swP5WN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prity_output(query:str,response:str):\n",
        "    # remove <bos>... tags\n",
        "    print(f\"Query: {query}\")\n",
        "    print(\"Response: \")\n",
        "    response = response.replace(\"<bos>\",\"\").replace(\"<|endoftext|>\",\"\").replace(\"</s>\",\"\")\n",
        "    display(Markdown(response))\n",
        "\n"
      ],
      "metadata": {
        "id": "6WmayYvLQWjs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_file()->str:\n",
        "    uploaded = files.upload()\n",
        "    return list(uploaded.keys())[0]"
      ],
      "metadata": {
        "id": "AvD72f1IAEit"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start with pdf\n",
        "def start_with_pdf():\n",
        "    global chunk_embeddings,chunk_list\n",
        "    print(\"Upload PDF File Below.\")\n",
        "    pdf_name = upload_file()\n",
        "    print(\"[INFO] PDF Uploaded Successfully, Processing PDF.\")\n",
        "    page_list = extract_text_from_pdf(pdf_name)\n",
        "    chunk_list = make_chunks(page_list)\n",
        "\n",
        "    print(\"[INFO] Creating embedings from PDF.\")\n",
        "    chunk_list = create_embeddings(chunk_list)\n",
        "    print(\"[INFO] Embeddings Created Successfully, Saving Embeddings.\")\n",
        "    save_embeddings(chunk_list)\n",
        "    # give option to download embeddings\n",
        "    print()\n",
        "    choice = input(\"Do you want to download embeddings? (y/n) :\")\n",
        "    if choice[0].lower() == \"y\":\n",
        "        files.download('embeddings.csv')\n",
        "        print(\"[INFO] Embeddings Downloaded Successfully, If not then you can find it in sidebar in files option.\")\n",
        "    else:\n",
        "        print(\"[INFO] You can find embeddings in files option in sidebar.\")\n",
        "\n",
        "    # make chunk embeddings, chunk list as global\n",
        "    numpy_embeddings = np.array([chunk['embedding'] for chunk in tqdm(chunk_list)])\n",
        "    chunk_embeddings = torch.tensor(numpy_embeddings, dtype=torch.float32).to(device)\n",
        "    # complete\n",
        "    print(\"[INFO] PDF Processing Completed Successfully.\")\n",
        "\n",
        "# start with embeddings\n",
        "def start_with_embeddings():\n",
        "    global chunk_embeddings,chunk_list\n",
        "    print(\"Upload Embeddings File Below(In CSV Format).\")\n",
        "    embedding_file = upload_file()\n",
        "    print(\"[INFO] Embeddings Uploaded Successfully, Loading Embeddings.\")\n",
        "    chunk_list = load_embeddings(embedding_file)\n",
        "    # chunk_embeddings = torch.tensor([chunk['embedding'] for chunk in chunk_list],dtype=torch.float32).to(device)\n",
        "    # Convert the list of NumPy arrays into a single NumPy array\n",
        "    numpy_embeddings = np.array([chunk['embedding'] for chunk in tqdm(chunk_list)])\n",
        "    chunk_embeddings = torch.tensor(numpy_embeddings, dtype=torch.float32).to(device)\n",
        "\n",
        "    print(\"[INFO] Embeddings Loaded Successfully\")\n",
        "\n",
        "def start_with_embeddings_without_upload():\n",
        "    global chunk_embeddings,chunk_list\n",
        "    print(\"[INFO] Embeddings Uploaded Successfully, Loading Embeddings.\")\n",
        "    chunk_list = load_embeddings(\"embeddings.csv\")\n",
        "    # chunk_embeddings = torch.tensor([chunk['embedding'] for chunk in chunk_list],dtype=torch.float32).to(device)\n",
        "    # Convert the list of NumPy arrays into a single NumPy array\n",
        "    numpy_embeddings = np.array([chunk['embedding'] for chunk in tqdm(chunk_list)])\n",
        "    chunk_embeddings = torch.tensor(numpy_embeddings, dtype=torch.float32).to(device)\n",
        "\n",
        "    print(\"[INFO] Embeddings Loaded Successfully\")"
      ],
      "metadata": {
        "id": "gMz-ILGL-edL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Choose option from Below\")\n",
        "print(\"1. Use PDF\")\n",
        "print(\"2. Use Existing Embeddings\")\n",
        "print(\"3. Use Existing Embeddings Without Uploading\")\n",
        "choice = input(\"Enter your choice: \")\n",
        "if choice == \"1\":\n",
        "    start_with_pdf()\n",
        "elif choice == \"2\":\n",
        "    start_with_embeddings()\n",
        "elif choice == \"3\":\n",
        "    start_with_embeddings_without_upload()\n",
        "else:\n",
        "    print(\"Invalid Choice\")"
      ],
      "metadata": {
        "id": "Mbx3r71pQPaw",
        "outputId": "d8c07dea-1fb1-40d5-a1d3-874c352455bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "c4d6c10a539b40b8abe4f7b2f5833e8f",
            "4dfeb39521144430a509702c0931a63e",
            "c0e558a3609d44b0b51c8bc17d1aa3e2",
            "be6b56b55ee54f6dba16289aaa850152",
            "dce2e74e2b2b4883a3eac2fb6e218500",
            "b406127e58f848629ffe8dbf99e72cb7",
            "5baa48e91c5b456e913b4fb17392fb19",
            "5fd3c9254d3d4d40bb922a4102a1ee37",
            "57d84b6bbc174a6e96b67e7a4797518d",
            "d719b751ef644aa4baff4ed2148ea1c5",
            "91691a65449b4bf096e1d0ab47d327ea"
          ]
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choose option from Below\n",
            "1. Use PDF\n",
            "2. Use Existing Embeddings\n",
            "3. Use Existing Embeddings Without Uploading\n",
            "Enter your choice: 3\n",
            "[INFO] Embeddings Uploaded Successfully, Loading Embeddings.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/56 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4d6c10a539b40b8abe4f7b2f5833e8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Embeddings Loaded Successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "query = input(\"Enter Question to PDF:\")\n",
        "prity_output(query,ask(query,chunk_embeddings,chunk_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFrHeFXTQADt",
        "outputId": "c6eb7dc3-54d6-45fe-b2eb-5b60c7217767"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Question to PDF:what is target function and its importance\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ef0cdc97af2a44439324f2547fb94f8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_abe3f5a3a8c5421aaaa2003aa067ca6b",
              "IPY_MODEL_47d9c44537cf4b8faba1554cd5f136db",
              "IPY_MODEL_6832dc89c35f4d7788a23e5140b3ef8f"
            ],
            "layout": "IPY_MODEL_5c85d7472a8b482fbbe28b9dc3e3fb87"
          }
        },
        "abe3f5a3a8c5421aaaa2003aa067ca6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_286b2dd8693841c78a0ac6fa18bfe756",
            "placeholder": "​",
            "style": "IPY_MODEL_36b3909b3c7248f6801891283e1e3462",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "47d9c44537cf4b8faba1554cd5f136db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_418a017529a74a848100fc0578f5cf81",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_005cad0ea75d45ee9891a0a73a5ec711",
            "value": 2
          }
        },
        "6832dc89c35f4d7788a23e5140b3ef8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e223239ac1504ec5999e4089c018236c",
            "placeholder": "​",
            "style": "IPY_MODEL_7f473623b581414ebbb0fe79d414c7b8",
            "value": " 2/2 [00:38&lt;00:00, 16.28s/it]"
          }
        },
        "5c85d7472a8b482fbbe28b9dc3e3fb87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "286b2dd8693841c78a0ac6fa18bfe756": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36b3909b3c7248f6801891283e1e3462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "418a017529a74a848100fc0578f5cf81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "005cad0ea75d45ee9891a0a73a5ec711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e223239ac1504ec5999e4089c018236c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f473623b581414ebbb0fe79d414c7b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4d6c10a539b40b8abe4f7b2f5833e8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4dfeb39521144430a509702c0931a63e",
              "IPY_MODEL_c0e558a3609d44b0b51c8bc17d1aa3e2",
              "IPY_MODEL_be6b56b55ee54f6dba16289aaa850152"
            ],
            "layout": "IPY_MODEL_dce2e74e2b2b4883a3eac2fb6e218500"
          }
        },
        "4dfeb39521144430a509702c0931a63e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b406127e58f848629ffe8dbf99e72cb7",
            "placeholder": "​",
            "style": "IPY_MODEL_5baa48e91c5b456e913b4fb17392fb19",
            "value": "100%"
          }
        },
        "c0e558a3609d44b0b51c8bc17d1aa3e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fd3c9254d3d4d40bb922a4102a1ee37",
            "max": 56,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57d84b6bbc174a6e96b67e7a4797518d",
            "value": 56
          }
        },
        "be6b56b55ee54f6dba16289aaa850152": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d719b751ef644aa4baff4ed2148ea1c5",
            "placeholder": "​",
            "style": "IPY_MODEL_91691a65449b4bf096e1d0ab47d327ea",
            "value": " 56/56 [00:00&lt;00:00, 676.51it/s]"
          }
        },
        "dce2e74e2b2b4883a3eac2fb6e218500": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b406127e58f848629ffe8dbf99e72cb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5baa48e91c5b456e913b4fb17392fb19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fd3c9254d3d4d40bb922a4102a1ee37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57d84b6bbc174a6e96b67e7a4797518d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d719b751ef644aa4baff4ed2148ea1c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91691a65449b4bf096e1d0ab47d327ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}